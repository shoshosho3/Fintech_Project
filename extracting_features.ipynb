{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T12:45:15.953938Z",
     "start_time": "2024-07-29T12:45:06.054399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "91748062e129957a",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T12:47:24.208581Z",
     "start_time": "2024-07-29T12:47:23.279618Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the data from data.xlsx\n",
    "data = pd.read_excel('data.xlsx')\n",
    "\n",
    "# getting the 'headline' column\n",
    "headlines = data['headline']"
   ],
   "id": "7feadb38f15dc6c5",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T13:01:00.242281Z",
     "start_time": "2024-07-29T12:49:09.684848Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def get_bert_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=50)\n",
    "    outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
    "\n",
    "# Apply BERT embeddings\n",
    "bert_embeddings = headlines.apply(get_bert_embeddings)\n",
    "bert_df = pd.DataFrame(bert_embeddings.tolist(), columns=[f'bert_{i}' for i in range(bert_embeddings[0].shape[1])])\n",
    "df = pd.concat([data, bert_df], axis=1)"
   ],
   "id": "bcdc774780f2c178",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b77f293287d043e180246d85291613bc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c82c489af27c41a6b8c0693c084d0b4e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2b77f359c19647ccbe775e7e63a21c12"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "47ff37a298aa4929a5eee917a0ebec33"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ba0ddd13969c4a7bada8cc52470f1047"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Must pass 2-d input. shape=(12330, 1, 768)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 14\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m# Apply BERT embeddings\u001B[39;00m\n\u001B[1;32m     13\u001B[0m bert_embeddings \u001B[38;5;241m=\u001B[39m headlines\u001B[38;5;241m.\u001B[39mapply(get_bert_embeddings)\n\u001B[0;32m---> 14\u001B[0m bert_df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDataFrame\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbert_embeddings\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtolist\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbert_\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mi\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mrange\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mbert_embeddings\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     15\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat([data, bert_df], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/Fintech_Project/.venv/lib/python3.11/site-packages/pandas/core/frame.py:867\u001B[0m, in \u001B[0;36mDataFrame.__init__\u001B[0;34m(self, data, index, columns, dtype, copy)\u001B[0m\n\u001B[1;32m    859\u001B[0m         mgr \u001B[38;5;241m=\u001B[39m arrays_to_mgr(\n\u001B[1;32m    860\u001B[0m             arrays,\n\u001B[1;32m    861\u001B[0m             columns,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    864\u001B[0m             typ\u001B[38;5;241m=\u001B[39mmanager,\n\u001B[1;32m    865\u001B[0m         )\n\u001B[1;32m    866\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 867\u001B[0m         mgr \u001B[38;5;241m=\u001B[39m \u001B[43mndarray_to_mgr\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    868\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    869\u001B[0m \u001B[43m            \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    870\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    871\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    872\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    873\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtyp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmanager\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    874\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    875\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    876\u001B[0m     mgr \u001B[38;5;241m=\u001B[39m dict_to_mgr(\n\u001B[1;32m    877\u001B[0m         {},\n\u001B[1;32m    878\u001B[0m         index,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    881\u001B[0m         typ\u001B[38;5;241m=\u001B[39mmanager,\n\u001B[1;32m    882\u001B[0m     )\n",
      "File \u001B[0;32m~/PycharmProjects/Fintech_Project/.venv/lib/python3.11/site-packages/pandas/core/internals/construction.py:319\u001B[0m, in \u001B[0;36mndarray_to_mgr\u001B[0;34m(values, index, columns, dtype, copy, typ)\u001B[0m\n\u001B[1;32m    314\u001B[0m     values \u001B[38;5;241m=\u001B[39m _ensure_2d(values)\n\u001B[1;32m    316\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    317\u001B[0m     \u001B[38;5;66;03m# by definition an array here\u001B[39;00m\n\u001B[1;32m    318\u001B[0m     \u001B[38;5;66;03m# the dtypes will be coerced to a single dtype\u001B[39;00m\n\u001B[0;32m--> 319\u001B[0m     values \u001B[38;5;241m=\u001B[39m \u001B[43m_prep_ndarraylike\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy_on_sanitize\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    321\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m values\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m!=\u001B[39m dtype:\n\u001B[1;32m    322\u001B[0m     \u001B[38;5;66;03m# GH#40110 see similar check inside sanitize_array\u001B[39;00m\n\u001B[1;32m    323\u001B[0m     values \u001B[38;5;241m=\u001B[39m sanitize_array(\n\u001B[1;32m    324\u001B[0m         values,\n\u001B[1;32m    325\u001B[0m         \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    328\u001B[0m         allow_2d\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    329\u001B[0m     )\n",
      "File \u001B[0;32m~/PycharmProjects/Fintech_Project/.venv/lib/python3.11/site-packages/pandas/core/internals/construction.py:582\u001B[0m, in \u001B[0;36m_prep_ndarraylike\u001B[0;34m(values, copy)\u001B[0m\n\u001B[1;32m    579\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    580\u001B[0m     values \u001B[38;5;241m=\u001B[39m convert(values)\n\u001B[0;32m--> 582\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_ensure_2d\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/Fintech_Project/.venv/lib/python3.11/site-packages/pandas/core/internals/construction.py:592\u001B[0m, in \u001B[0;36m_ensure_2d\u001B[0;34m(values)\u001B[0m\n\u001B[1;32m    590\u001B[0m     values \u001B[38;5;241m=\u001B[39m values\u001B[38;5;241m.\u001B[39mreshape((values\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;241m1\u001B[39m))\n\u001B[1;32m    591\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m values\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m2\u001B[39m:\n\u001B[0;32m--> 592\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMust pass 2-d input. shape=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvalues\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    593\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m values\n",
      "\u001B[0;31mValueError\u001B[0m: Must pass 2-d input. shape=(12330, 1, 768)"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T13:16:07.792069Z",
     "start_time": "2024-07-29T13:16:07.710086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert the Series to a NumPy array and reshape it\n",
    "bert_embeddings_reshaped = np.vstack(bert_embeddings.values).reshape(bert_embeddings.shape[0], -1)\n",
    "\n",
    "# Create the DataFrame\n",
    "bert_df = pd.DataFrame(bert_embeddings_reshaped, columns=[f'bert_{i}' for i in range(bert_embeddings_reshaped.shape[1])])"
   ],
   "id": "79dd7723134ac444",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         bert_0    bert_1    bert_2    bert_3    bert_4    bert_5    bert_6  \\\n",
      "0      0.255907  0.103649  0.378245 -0.008151  0.276857 -0.028673 -0.048503   \n",
      "1      0.189094  0.014033  0.132377  0.080640  0.215747  0.052356 -0.064865   \n",
      "2      0.086544  0.109378  0.288210  0.246598  0.247313 -0.061815 -0.283035   \n",
      "3     -0.305897  0.175409  0.046135  0.039006  0.228466 -0.206569  0.081190   \n",
      "4     -0.408944 -0.179478 -0.285059  0.092292  0.443659 -0.211175 -0.223040   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "12325  0.126108  0.118994  0.401555 -0.030231  0.156685 -0.216203  0.025891   \n",
      "12326  0.083364  0.030812  0.638860  0.007236  0.236335 -0.053290 -0.213877   \n",
      "12327  0.139710 -0.303138  0.375856  0.025938  0.320123 -0.257147 -0.168615   \n",
      "12328 -0.067297 -0.405788 -0.284279 -0.092923  0.191737  0.290780  0.032943   \n",
      "12329 -0.012733 -0.479689  0.257645  0.067756  0.210853  0.053492 -0.096735   \n",
      "\n",
      "         bert_7    bert_8    bert_9  ...  bert_758  bert_759  bert_760  \\\n",
      "0      0.404394  0.114886 -0.068855  ...  0.032861  0.213583  0.262270   \n",
      "1      0.343320 -0.004229  0.156094  ... -0.058016  0.085318  0.184438   \n",
      "2      0.441026  0.174515 -0.189816  ... -0.110791  0.112688  0.118005   \n",
      "3      0.127606 -0.149673 -0.252358  ...  0.051202  0.215871 -0.075383   \n",
      "4      0.537517 -0.237419 -0.071347  ...  0.042596  0.318495  0.086143   \n",
      "...         ...       ...       ...  ...       ...       ...       ...   \n",
      "12325  0.167001  0.353846 -0.175120  ... -0.046315 -0.081767 -0.276583   \n",
      "12326  0.169207 -0.082430  0.122632  ... -0.064722 -0.011666 -0.075684   \n",
      "12327  0.266387 -0.022330 -0.187424  ...  0.040266  0.086718 -0.165790   \n",
      "12328  0.218219 -0.160524 -0.214046  ...  0.198265 -0.157304  0.178743   \n",
      "12329  0.403005 -0.722375 -0.248802  ...  0.062317  0.085671  0.326690   \n",
      "\n",
      "       bert_761  bert_762  bert_763  bert_764  bert_765  bert_766  bert_767  \n",
      "0     -0.446573  0.365529 -0.221021  0.103452 -0.276600  0.327449  0.056182  \n",
      "1     -0.248667  0.463884 -0.189807  0.291041 -0.207908  0.224768  0.242797  \n",
      "2     -0.471153  0.203770 -0.219168  0.225092 -0.187056  0.344419 -0.005055  \n",
      "3     -0.072532  0.037590 -0.133884 -0.197072 -0.213612  0.170306  0.146870  \n",
      "4     -0.182895  0.280002 -0.150981 -0.174248 -0.083836  0.213137  0.047022  \n",
      "...         ...       ...       ...       ...       ...       ...       ...  \n",
      "12325 -0.176657  0.083011 -0.213803 -0.090200 -0.090316  0.070770 -0.139745  \n",
      "12326 -0.351367  0.095219 -0.258650  0.033707 -0.108736  0.121511 -0.039834  \n",
      "12327 -0.453710  0.203251 -0.348584 -0.104239 -0.058146  0.186400  0.013838  \n",
      "12328 -0.330695 -0.070403 -0.031711 -0.251284 -0.080934  0.026316 -0.056993  \n",
      "12329 -0.126228  0.216594  0.016412  0.012447 -0.274096 -0.227791 -0.468656  \n",
      "\n",
      "[12330 rows x 768 columns]\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T13:16:40.026286Z",
     "start_time": "2024-07-29T13:16:39.920433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = pd.concat([data, bert_df], axis=1)\n",
    "data"
   ],
   "id": "688518b560a4ee32",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                headline       date stock  \\\n",
       "0      Sprucegrove Investment Management Ltd Buys Rya... 2020-05-15  ABEV   \n",
       "1      Westwood Global Investments, LLC Buys Ambev SA... 2020-05-14  ABEV   \n",
       "2      First Eagle Investment Management, LLC Buys Am... 2020-05-12  ABEV   \n",
       "3      Ambev Reports —…—… First Quarter Results Under... 2020-05-07  ABEV   \n",
       "4      5 Latin American Stocks to Consider in Honor o... 2020-05-05  ABEV   \n",
       "...                                                  ...        ...   ...   \n",
       "12325  AdvisorShares Launches Global Alpha and Beta E... 2012-07-11   VOX   \n",
       "12326       Towers Of Power (VOX, T, AMT, CCI, SBAC, VZ) 2012-04-30   VOX   \n",
       "12327  ETF Trading Report: Telecom, Healthcare ETFs I... 2012-04-19   VOX   \n",
       "12328              Dialing Up Defense Or Disappointment? 2012-04-11   VOX   \n",
       "12329                 Vanguard Sector Funds Get Facelift 2010-03-04   VOX   \n",
       "\n",
       "      adjusted_datetime  opening_price  closing_price    bert_0    bert_1  \\\n",
       "0            2020-05-15       2.020000       2.020000  0.255907  0.103649   \n",
       "1            2020-05-14       1.970000       2.040000  0.189094  0.014033   \n",
       "2            2020-05-12       2.110000       2.020000  0.086544  0.109378   \n",
       "3            2020-05-07       2.100000       2.000000 -0.305897  0.175409   \n",
       "4            2020-05-05       2.180000       2.150000 -0.408944 -0.179478   \n",
       "...                 ...            ...            ...       ...       ...   \n",
       "12325        2012-07-11      69.800003      69.239998  0.126108  0.118994   \n",
       "12326        2012-04-30      64.379997      64.769997  0.083364  0.030812   \n",
       "12327        2012-04-19      63.439999      62.919998  0.139710 -0.303138   \n",
       "12328        2012-04-11      63.180000      63.669998 -0.067297 -0.405788   \n",
       "12329        2010-03-04      53.490002      53.529999 -0.012733 -0.479689   \n",
       "\n",
       "         bert_2    bert_3  ...  bert_758  bert_759  bert_760  bert_761  \\\n",
       "0      0.378245 -0.008151  ...  0.032861  0.213583  0.262270 -0.446573   \n",
       "1      0.132377  0.080640  ... -0.058016  0.085318  0.184438 -0.248667   \n",
       "2      0.288210  0.246598  ... -0.110791  0.112688  0.118005 -0.471153   \n",
       "3      0.046135  0.039006  ...  0.051202  0.215871 -0.075383 -0.072532   \n",
       "4     -0.285059  0.092292  ...  0.042596  0.318495  0.086143 -0.182895   \n",
       "...         ...       ...  ...       ...       ...       ...       ...   \n",
       "12325  0.401555 -0.030231  ... -0.046315 -0.081767 -0.276583 -0.176657   \n",
       "12326  0.638860  0.007236  ... -0.064722 -0.011666 -0.075684 -0.351367   \n",
       "12327  0.375856  0.025938  ...  0.040266  0.086718 -0.165790 -0.453710   \n",
       "12328 -0.284279 -0.092923  ...  0.198265 -0.157304  0.178743 -0.330695   \n",
       "12329  0.257645  0.067756  ...  0.062317  0.085671  0.326690 -0.126228   \n",
       "\n",
       "       bert_762  bert_763  bert_764  bert_765  bert_766  bert_767  \n",
       "0      0.365529 -0.221021  0.103452 -0.276600  0.327449  0.056182  \n",
       "1      0.463884 -0.189807  0.291041 -0.207908  0.224768  0.242797  \n",
       "2      0.203770 -0.219168  0.225092 -0.187056  0.344419 -0.005055  \n",
       "3      0.037590 -0.133884 -0.197072 -0.213612  0.170306  0.146870  \n",
       "4      0.280002 -0.150981 -0.174248 -0.083836  0.213137  0.047022  \n",
       "...         ...       ...       ...       ...       ...       ...  \n",
       "12325  0.083011 -0.213803 -0.090200 -0.090316  0.070770 -0.139745  \n",
       "12326  0.095219 -0.258650  0.033707 -0.108736  0.121511 -0.039834  \n",
       "12327  0.203251 -0.348584 -0.104239 -0.058146  0.186400  0.013838  \n",
       "12328 -0.070403 -0.031711 -0.251284 -0.080934  0.026316 -0.056993  \n",
       "12329  0.216594  0.016412  0.012447 -0.274096 -0.227791 -0.468656  \n",
       "\n",
       "[12330 rows x 774 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>date</th>\n",
       "      <th>stock</th>\n",
       "      <th>adjusted_datetime</th>\n",
       "      <th>opening_price</th>\n",
       "      <th>closing_price</th>\n",
       "      <th>bert_0</th>\n",
       "      <th>bert_1</th>\n",
       "      <th>bert_2</th>\n",
       "      <th>bert_3</th>\n",
       "      <th>...</th>\n",
       "      <th>bert_758</th>\n",
       "      <th>bert_759</th>\n",
       "      <th>bert_760</th>\n",
       "      <th>bert_761</th>\n",
       "      <th>bert_762</th>\n",
       "      <th>bert_763</th>\n",
       "      <th>bert_764</th>\n",
       "      <th>bert_765</th>\n",
       "      <th>bert_766</th>\n",
       "      <th>bert_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sprucegrove Investment Management Ltd Buys Rya...</td>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>ABEV</td>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>2.020000</td>\n",
       "      <td>2.020000</td>\n",
       "      <td>0.255907</td>\n",
       "      <td>0.103649</td>\n",
       "      <td>0.378245</td>\n",
       "      <td>-0.008151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032861</td>\n",
       "      <td>0.213583</td>\n",
       "      <td>0.262270</td>\n",
       "      <td>-0.446573</td>\n",
       "      <td>0.365529</td>\n",
       "      <td>-0.221021</td>\n",
       "      <td>0.103452</td>\n",
       "      <td>-0.276600</td>\n",
       "      <td>0.327449</td>\n",
       "      <td>0.056182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Westwood Global Investments, LLC Buys Ambev SA...</td>\n",
       "      <td>2020-05-14</td>\n",
       "      <td>ABEV</td>\n",
       "      <td>2020-05-14</td>\n",
       "      <td>1.970000</td>\n",
       "      <td>2.040000</td>\n",
       "      <td>0.189094</td>\n",
       "      <td>0.014033</td>\n",
       "      <td>0.132377</td>\n",
       "      <td>0.080640</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058016</td>\n",
       "      <td>0.085318</td>\n",
       "      <td>0.184438</td>\n",
       "      <td>-0.248667</td>\n",
       "      <td>0.463884</td>\n",
       "      <td>-0.189807</td>\n",
       "      <td>0.291041</td>\n",
       "      <td>-0.207908</td>\n",
       "      <td>0.224768</td>\n",
       "      <td>0.242797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>First Eagle Investment Management, LLC Buys Am...</td>\n",
       "      <td>2020-05-12</td>\n",
       "      <td>ABEV</td>\n",
       "      <td>2020-05-12</td>\n",
       "      <td>2.110000</td>\n",
       "      <td>2.020000</td>\n",
       "      <td>0.086544</td>\n",
       "      <td>0.109378</td>\n",
       "      <td>0.288210</td>\n",
       "      <td>0.246598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.110791</td>\n",
       "      <td>0.112688</td>\n",
       "      <td>0.118005</td>\n",
       "      <td>-0.471153</td>\n",
       "      <td>0.203770</td>\n",
       "      <td>-0.219168</td>\n",
       "      <td>0.225092</td>\n",
       "      <td>-0.187056</td>\n",
       "      <td>0.344419</td>\n",
       "      <td>-0.005055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ambev Reports —…—… First Quarter Results Under...</td>\n",
       "      <td>2020-05-07</td>\n",
       "      <td>ABEV</td>\n",
       "      <td>2020-05-07</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-0.305897</td>\n",
       "      <td>0.175409</td>\n",
       "      <td>0.046135</td>\n",
       "      <td>0.039006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051202</td>\n",
       "      <td>0.215871</td>\n",
       "      <td>-0.075383</td>\n",
       "      <td>-0.072532</td>\n",
       "      <td>0.037590</td>\n",
       "      <td>-0.133884</td>\n",
       "      <td>-0.197072</td>\n",
       "      <td>-0.213612</td>\n",
       "      <td>0.170306</td>\n",
       "      <td>0.146870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5 Latin American Stocks to Consider in Honor o...</td>\n",
       "      <td>2020-05-05</td>\n",
       "      <td>ABEV</td>\n",
       "      <td>2020-05-05</td>\n",
       "      <td>2.180000</td>\n",
       "      <td>2.150000</td>\n",
       "      <td>-0.408944</td>\n",
       "      <td>-0.179478</td>\n",
       "      <td>-0.285059</td>\n",
       "      <td>0.092292</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042596</td>\n",
       "      <td>0.318495</td>\n",
       "      <td>0.086143</td>\n",
       "      <td>-0.182895</td>\n",
       "      <td>0.280002</td>\n",
       "      <td>-0.150981</td>\n",
       "      <td>-0.174248</td>\n",
       "      <td>-0.083836</td>\n",
       "      <td>0.213137</td>\n",
       "      <td>0.047022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12325</th>\n",
       "      <td>AdvisorShares Launches Global Alpha and Beta E...</td>\n",
       "      <td>2012-07-11</td>\n",
       "      <td>VOX</td>\n",
       "      <td>2012-07-11</td>\n",
       "      <td>69.800003</td>\n",
       "      <td>69.239998</td>\n",
       "      <td>0.126108</td>\n",
       "      <td>0.118994</td>\n",
       "      <td>0.401555</td>\n",
       "      <td>-0.030231</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046315</td>\n",
       "      <td>-0.081767</td>\n",
       "      <td>-0.276583</td>\n",
       "      <td>-0.176657</td>\n",
       "      <td>0.083011</td>\n",
       "      <td>-0.213803</td>\n",
       "      <td>-0.090200</td>\n",
       "      <td>-0.090316</td>\n",
       "      <td>0.070770</td>\n",
       "      <td>-0.139745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12326</th>\n",
       "      <td>Towers Of Power (VOX, T, AMT, CCI, SBAC, VZ)</td>\n",
       "      <td>2012-04-30</td>\n",
       "      <td>VOX</td>\n",
       "      <td>2012-04-30</td>\n",
       "      <td>64.379997</td>\n",
       "      <td>64.769997</td>\n",
       "      <td>0.083364</td>\n",
       "      <td>0.030812</td>\n",
       "      <td>0.638860</td>\n",
       "      <td>0.007236</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064722</td>\n",
       "      <td>-0.011666</td>\n",
       "      <td>-0.075684</td>\n",
       "      <td>-0.351367</td>\n",
       "      <td>0.095219</td>\n",
       "      <td>-0.258650</td>\n",
       "      <td>0.033707</td>\n",
       "      <td>-0.108736</td>\n",
       "      <td>0.121511</td>\n",
       "      <td>-0.039834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12327</th>\n",
       "      <td>ETF Trading Report: Telecom, Healthcare ETFs I...</td>\n",
       "      <td>2012-04-19</td>\n",
       "      <td>VOX</td>\n",
       "      <td>2012-04-19</td>\n",
       "      <td>63.439999</td>\n",
       "      <td>62.919998</td>\n",
       "      <td>0.139710</td>\n",
       "      <td>-0.303138</td>\n",
       "      <td>0.375856</td>\n",
       "      <td>0.025938</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040266</td>\n",
       "      <td>0.086718</td>\n",
       "      <td>-0.165790</td>\n",
       "      <td>-0.453710</td>\n",
       "      <td>0.203251</td>\n",
       "      <td>-0.348584</td>\n",
       "      <td>-0.104239</td>\n",
       "      <td>-0.058146</td>\n",
       "      <td>0.186400</td>\n",
       "      <td>0.013838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12328</th>\n",
       "      <td>Dialing Up Defense Or Disappointment?</td>\n",
       "      <td>2012-04-11</td>\n",
       "      <td>VOX</td>\n",
       "      <td>2012-04-11</td>\n",
       "      <td>63.180000</td>\n",
       "      <td>63.669998</td>\n",
       "      <td>-0.067297</td>\n",
       "      <td>-0.405788</td>\n",
       "      <td>-0.284279</td>\n",
       "      <td>-0.092923</td>\n",
       "      <td>...</td>\n",
       "      <td>0.198265</td>\n",
       "      <td>-0.157304</td>\n",
       "      <td>0.178743</td>\n",
       "      <td>-0.330695</td>\n",
       "      <td>-0.070403</td>\n",
       "      <td>-0.031711</td>\n",
       "      <td>-0.251284</td>\n",
       "      <td>-0.080934</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>-0.056993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12329</th>\n",
       "      <td>Vanguard Sector Funds Get Facelift</td>\n",
       "      <td>2010-03-04</td>\n",
       "      <td>VOX</td>\n",
       "      <td>2010-03-04</td>\n",
       "      <td>53.490002</td>\n",
       "      <td>53.529999</td>\n",
       "      <td>-0.012733</td>\n",
       "      <td>-0.479689</td>\n",
       "      <td>0.257645</td>\n",
       "      <td>0.067756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062317</td>\n",
       "      <td>0.085671</td>\n",
       "      <td>0.326690</td>\n",
       "      <td>-0.126228</td>\n",
       "      <td>0.216594</td>\n",
       "      <td>0.016412</td>\n",
       "      <td>0.012447</td>\n",
       "      <td>-0.274096</td>\n",
       "      <td>-0.227791</td>\n",
       "      <td>-0.468656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12330 rows × 774 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T13:55:03.311744Z",
     "start_time": "2024-07-29T13:43:38.402271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "\n",
    "# Initialize RoBERTa tokenizer and model\n",
    "tokenizer_roberta = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model_roberta = RobertaModel.from_pretrained('roberta-base')\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('mps')\n",
    "model_roberta = model_roberta.to(device)\n",
    "\n",
    "# Function to get RoBERTa embeddings\n",
    "def get_roberta_embeddings(text):\n",
    "    inputs = tokenizer_roberta(text, return_tensors='pt', truncation=True, padding=True, max_length=50).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model_roberta(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).cpu().numpy()"
   ],
   "id": "2f216b8d64149d22",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "543c3ed5796748e4992c48a5682ca171"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e8b056114a3c4e3ab26ef81730abcc9a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fe7c5d5831a149b3af8df6c534e19328"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6238bf9d53e64bbb92a84a1556203b28"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "492c8ace81734cb1afcb8ce0f35d2547"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "de3d6e4bde7444249ab2a3ea3ace8be7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T14:05:52.823878Z",
     "start_time": "2024-07-29T14:00:03.855591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "roberta_embeddings = headlines.apply(get_roberta_embeddings)\n",
    "roberta_embeddings_reshaped = np.vstack(roberta_embeddings.values).reshape(roberta_embeddings.shape[0], -1)\n",
    "roberta_df = pd.DataFrame(roberta_embeddings_reshaped, columns=[f'roberta_{i}' for i in range(roberta_embeddings_reshaped.shape[1])])"
   ],
   "id": "d979e5f045e2180d",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T14:07:27.148193Z",
     "start_time": "2024-07-29T14:07:27.055369Z"
    }
   },
   "cell_type": "code",
   "source": "roberta_df",
   "id": "cc7e52943d1acff1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       roberta_0  roberta_1  roberta_2  roberta_3  roberta_4  roberta_5  \\\n",
       "0      -0.008698   0.047732  -0.020773   0.043870   0.257866  -0.119137   \n",
       "1       0.012474   0.086053   0.037018   0.086625   0.054792  -0.076585   \n",
       "2       0.018468   0.103287   0.036900   0.081081   0.105985   0.064790   \n",
       "3       0.046941   0.101946  -0.021644   0.132030   0.237758  -0.033711   \n",
       "4       0.128761   0.201474   0.070045  -0.106207   0.129400   0.457412   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "12325   0.002212   0.153360  -0.026089   0.058496   0.075810   0.133279   \n",
       "12326   0.000228   0.112390  -0.003339   0.071011   0.037659   0.110403   \n",
       "12327   0.063129   0.179003   0.010075   0.064122  -0.067381   0.237346   \n",
       "12328  -0.017428  -0.014558   0.035954  -0.169393   0.461812   0.221540   \n",
       "12329  -0.099926   0.124495   0.033545  -0.120867   0.154348   0.153552   \n",
       "\n",
       "       roberta_6  roberta_7  roberta_8  roberta_9  ...  roberta_758  \\\n",
       "0       0.009067  -0.002964   0.003693   0.053707  ...     0.058707   \n",
       "1      -0.024295   0.129785   0.066270   0.029004  ...     0.094255   \n",
       "2      -0.047948   0.064791   0.115308   0.043047  ...     0.105063   \n",
       "3       0.009320  -0.019492   0.015086   0.105308  ...     0.023993   \n",
       "4       0.010283  -0.105423   0.205671   0.037495  ...    -0.101402   \n",
       "...          ...        ...        ...        ...  ...          ...   \n",
       "12325  -0.039119   0.125221   0.040539   0.117027  ...     0.076450   \n",
       "12326  -0.076773  -0.033375   0.042587  -0.008569  ...     0.001093   \n",
       "12327  -0.009871   0.007040   0.107013   0.148580  ...    -0.027807   \n",
       "12328  -0.000481  -0.152135   0.165171  -0.155005  ...     0.050695   \n",
       "12329   0.051131  -0.024554   0.124593  -0.005636  ...     0.092644   \n",
       "\n",
       "       roberta_759  roberta_760  roberta_761  roberta_762  roberta_763  \\\n",
       "0         0.049282     0.026407     0.034248     0.118110     0.166971   \n",
       "1        -0.016954     0.066492     0.048691     0.134696     0.177772   \n",
       "2        -0.039523     0.084372    -0.011546     0.062304     0.103159   \n",
       "3         0.112618     0.081958    -0.008981     0.072427     0.133495   \n",
       "4         0.024853    -0.104801    -0.055191     0.036767     0.170091   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "12325    -0.026319    -0.139397    -0.019582    -0.013003     0.087974   \n",
       "12326    -0.064768     0.042499    -0.024593    -0.076575    -0.034950   \n",
       "12327     0.021414    -0.116391    -0.026301    -0.079099     0.085786   \n",
       "12328    -0.017544     0.047002    -0.062714     0.123618     0.074212   \n",
       "12329    -0.012298    -0.095170    -0.030393     0.082480     0.114413   \n",
       "\n",
       "       roberta_764  roberta_765  roberta_766  roberta_767  \n",
       "0         0.169259     0.027838     0.004437     0.094532  \n",
       "1         0.164367    -0.150063     0.085368     0.072673  \n",
       "2         0.278716    -0.026584     0.025919     0.117307  \n",
       "3         0.398740     0.190809     0.004323     0.205453  \n",
       "4         0.007016     0.109526     0.029001     0.015806  \n",
       "...            ...          ...          ...          ...  \n",
       "12325     0.269911    -0.032082    -0.020554     0.121728  \n",
       "12326     0.114762     0.058225    -0.045030     0.029916  \n",
       "12327     0.311818     0.347366    -0.046354     0.102883  \n",
       "12328     0.134851     0.101637     0.032678     0.036828  \n",
       "12329     0.450878     0.129149     0.002945     0.120372  \n",
       "\n",
       "[12330 rows x 768 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roberta_0</th>\n",
       "      <th>roberta_1</th>\n",
       "      <th>roberta_2</th>\n",
       "      <th>roberta_3</th>\n",
       "      <th>roberta_4</th>\n",
       "      <th>roberta_5</th>\n",
       "      <th>roberta_6</th>\n",
       "      <th>roberta_7</th>\n",
       "      <th>roberta_8</th>\n",
       "      <th>roberta_9</th>\n",
       "      <th>...</th>\n",
       "      <th>roberta_758</th>\n",
       "      <th>roberta_759</th>\n",
       "      <th>roberta_760</th>\n",
       "      <th>roberta_761</th>\n",
       "      <th>roberta_762</th>\n",
       "      <th>roberta_763</th>\n",
       "      <th>roberta_764</th>\n",
       "      <th>roberta_765</th>\n",
       "      <th>roberta_766</th>\n",
       "      <th>roberta_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.008698</td>\n",
       "      <td>0.047732</td>\n",
       "      <td>-0.020773</td>\n",
       "      <td>0.043870</td>\n",
       "      <td>0.257866</td>\n",
       "      <td>-0.119137</td>\n",
       "      <td>0.009067</td>\n",
       "      <td>-0.002964</td>\n",
       "      <td>0.003693</td>\n",
       "      <td>0.053707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058707</td>\n",
       "      <td>0.049282</td>\n",
       "      <td>0.026407</td>\n",
       "      <td>0.034248</td>\n",
       "      <td>0.118110</td>\n",
       "      <td>0.166971</td>\n",
       "      <td>0.169259</td>\n",
       "      <td>0.027838</td>\n",
       "      <td>0.004437</td>\n",
       "      <td>0.094532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.012474</td>\n",
       "      <td>0.086053</td>\n",
       "      <td>0.037018</td>\n",
       "      <td>0.086625</td>\n",
       "      <td>0.054792</td>\n",
       "      <td>-0.076585</td>\n",
       "      <td>-0.024295</td>\n",
       "      <td>0.129785</td>\n",
       "      <td>0.066270</td>\n",
       "      <td>0.029004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094255</td>\n",
       "      <td>-0.016954</td>\n",
       "      <td>0.066492</td>\n",
       "      <td>0.048691</td>\n",
       "      <td>0.134696</td>\n",
       "      <td>0.177772</td>\n",
       "      <td>0.164367</td>\n",
       "      <td>-0.150063</td>\n",
       "      <td>0.085368</td>\n",
       "      <td>0.072673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.018468</td>\n",
       "      <td>0.103287</td>\n",
       "      <td>0.036900</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.105985</td>\n",
       "      <td>0.064790</td>\n",
       "      <td>-0.047948</td>\n",
       "      <td>0.064791</td>\n",
       "      <td>0.115308</td>\n",
       "      <td>0.043047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105063</td>\n",
       "      <td>-0.039523</td>\n",
       "      <td>0.084372</td>\n",
       "      <td>-0.011546</td>\n",
       "      <td>0.062304</td>\n",
       "      <td>0.103159</td>\n",
       "      <td>0.278716</td>\n",
       "      <td>-0.026584</td>\n",
       "      <td>0.025919</td>\n",
       "      <td>0.117307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.046941</td>\n",
       "      <td>0.101946</td>\n",
       "      <td>-0.021644</td>\n",
       "      <td>0.132030</td>\n",
       "      <td>0.237758</td>\n",
       "      <td>-0.033711</td>\n",
       "      <td>0.009320</td>\n",
       "      <td>-0.019492</td>\n",
       "      <td>0.015086</td>\n",
       "      <td>0.105308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023993</td>\n",
       "      <td>0.112618</td>\n",
       "      <td>0.081958</td>\n",
       "      <td>-0.008981</td>\n",
       "      <td>0.072427</td>\n",
       "      <td>0.133495</td>\n",
       "      <td>0.398740</td>\n",
       "      <td>0.190809</td>\n",
       "      <td>0.004323</td>\n",
       "      <td>0.205453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.128761</td>\n",
       "      <td>0.201474</td>\n",
       "      <td>0.070045</td>\n",
       "      <td>-0.106207</td>\n",
       "      <td>0.129400</td>\n",
       "      <td>0.457412</td>\n",
       "      <td>0.010283</td>\n",
       "      <td>-0.105423</td>\n",
       "      <td>0.205671</td>\n",
       "      <td>0.037495</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.101402</td>\n",
       "      <td>0.024853</td>\n",
       "      <td>-0.104801</td>\n",
       "      <td>-0.055191</td>\n",
       "      <td>0.036767</td>\n",
       "      <td>0.170091</td>\n",
       "      <td>0.007016</td>\n",
       "      <td>0.109526</td>\n",
       "      <td>0.029001</td>\n",
       "      <td>0.015806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12325</th>\n",
       "      <td>0.002212</td>\n",
       "      <td>0.153360</td>\n",
       "      <td>-0.026089</td>\n",
       "      <td>0.058496</td>\n",
       "      <td>0.075810</td>\n",
       "      <td>0.133279</td>\n",
       "      <td>-0.039119</td>\n",
       "      <td>0.125221</td>\n",
       "      <td>0.040539</td>\n",
       "      <td>0.117027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076450</td>\n",
       "      <td>-0.026319</td>\n",
       "      <td>-0.139397</td>\n",
       "      <td>-0.019582</td>\n",
       "      <td>-0.013003</td>\n",
       "      <td>0.087974</td>\n",
       "      <td>0.269911</td>\n",
       "      <td>-0.032082</td>\n",
       "      <td>-0.020554</td>\n",
       "      <td>0.121728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12326</th>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.112390</td>\n",
       "      <td>-0.003339</td>\n",
       "      <td>0.071011</td>\n",
       "      <td>0.037659</td>\n",
       "      <td>0.110403</td>\n",
       "      <td>-0.076773</td>\n",
       "      <td>-0.033375</td>\n",
       "      <td>0.042587</td>\n",
       "      <td>-0.008569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001093</td>\n",
       "      <td>-0.064768</td>\n",
       "      <td>0.042499</td>\n",
       "      <td>-0.024593</td>\n",
       "      <td>-0.076575</td>\n",
       "      <td>-0.034950</td>\n",
       "      <td>0.114762</td>\n",
       "      <td>0.058225</td>\n",
       "      <td>-0.045030</td>\n",
       "      <td>0.029916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12327</th>\n",
       "      <td>0.063129</td>\n",
       "      <td>0.179003</td>\n",
       "      <td>0.010075</td>\n",
       "      <td>0.064122</td>\n",
       "      <td>-0.067381</td>\n",
       "      <td>0.237346</td>\n",
       "      <td>-0.009871</td>\n",
       "      <td>0.007040</td>\n",
       "      <td>0.107013</td>\n",
       "      <td>0.148580</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027807</td>\n",
       "      <td>0.021414</td>\n",
       "      <td>-0.116391</td>\n",
       "      <td>-0.026301</td>\n",
       "      <td>-0.079099</td>\n",
       "      <td>0.085786</td>\n",
       "      <td>0.311818</td>\n",
       "      <td>0.347366</td>\n",
       "      <td>-0.046354</td>\n",
       "      <td>0.102883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12328</th>\n",
       "      <td>-0.017428</td>\n",
       "      <td>-0.014558</td>\n",
       "      <td>0.035954</td>\n",
       "      <td>-0.169393</td>\n",
       "      <td>0.461812</td>\n",
       "      <td>0.221540</td>\n",
       "      <td>-0.000481</td>\n",
       "      <td>-0.152135</td>\n",
       "      <td>0.165171</td>\n",
       "      <td>-0.155005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050695</td>\n",
       "      <td>-0.017544</td>\n",
       "      <td>0.047002</td>\n",
       "      <td>-0.062714</td>\n",
       "      <td>0.123618</td>\n",
       "      <td>0.074212</td>\n",
       "      <td>0.134851</td>\n",
       "      <td>0.101637</td>\n",
       "      <td>0.032678</td>\n",
       "      <td>0.036828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12329</th>\n",
       "      <td>-0.099926</td>\n",
       "      <td>0.124495</td>\n",
       "      <td>0.033545</td>\n",
       "      <td>-0.120867</td>\n",
       "      <td>0.154348</td>\n",
       "      <td>0.153552</td>\n",
       "      <td>0.051131</td>\n",
       "      <td>-0.024554</td>\n",
       "      <td>0.124593</td>\n",
       "      <td>-0.005636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092644</td>\n",
       "      <td>-0.012298</td>\n",
       "      <td>-0.095170</td>\n",
       "      <td>-0.030393</td>\n",
       "      <td>0.082480</td>\n",
       "      <td>0.114413</td>\n",
       "      <td>0.450878</td>\n",
       "      <td>0.129149</td>\n",
       "      <td>0.002945</td>\n",
       "      <td>0.120372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12330 rows × 768 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T14:14:07.206757Z",
     "start_time": "2024-07-29T14:09:04.529945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Initialize RoBERTa tokenizer and model\n",
    "auto_tokenizer = AutoTokenizer.from_pretrained(\"chrommium/bert-base-multilingual-cased-finetuned-news-headlines\")\n",
    "auto_model = AutoModel.from_pretrained(\"chrommium/bert-base-multilingual-cased-finetuned-news-headlines\")\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('mps')\n",
    "auto_model = auto_model.to(device)\n",
    "\n",
    "# Function to get RoBERTa embeddings\n",
    "def get_auto_embeddings(text):\n",
    "    inputs = auto_tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=50).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = auto_model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "\n",
    "# Example usage\n",
    "auto_embeddings = headlines.apply(get_auto_embeddings)\n",
    "auto_embeddings_reshaped = np.vstack(auto_embeddings.values).reshape(auto_embeddings.shape[0], -1)"
   ],
   "id": "c4ae6c1ae54faf66",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/333 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "970e705dbffd4aebbe38c13358eb5c9c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2c4142956ac84004b7c4807b8c2e844f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7734af2c93ca432eb66b505e5c9058c1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "403b84cb5a984adaa3be8b4b053eac92"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "79b43968cc9e4217b406f3bf9bc3a836"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/712M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ab4cc390956a49cb9e04c9882c13c3b1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T14:16:46.610906Z",
     "start_time": "2024-07-29T14:16:46.569613Z"
    }
   },
   "cell_type": "code",
   "source": [
    "auto_df = pd.DataFrame(auto_embeddings_reshaped, columns=[f'auto_{i}' for i in range(auto_embeddings_reshaped.shape[1])])\n",
    "auto_df"
   ],
   "id": "9d3a1dcd57ef1c7a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         auto_0    auto_1    auto_2    auto_3    auto_4    auto_5    auto_6  \\\n",
       "0     -0.446178 -1.030787  0.651053  0.131997  1.462828  0.029508 -0.295723   \n",
       "1     -0.465874 -1.181763  0.562184  0.369159  1.582658  0.103490 -0.280516   \n",
       "2     -0.398899 -1.068048  0.773323  0.165763  1.510350  0.011403 -0.299957   \n",
       "3     -0.327914 -0.916163  0.535471  0.040720  1.281561 -0.067109 -0.436066   \n",
       "4     -0.193191 -0.339105  0.701786  0.099271  1.795199 -0.328261 -0.968132   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "12325 -0.199234 -0.544771  1.052641  0.258894  1.709730  0.316471 -0.410517   \n",
       "12326 -0.544345 -0.855553  0.429286  0.262292  1.596824 -0.283487 -0.641597   \n",
       "12327 -0.238448 -0.706277  0.659115  0.194608  1.261518  0.047830 -0.307249   \n",
       "12328 -0.026563 -0.710416  0.770859  0.307719  0.958489  0.066654 -0.574208   \n",
       "12329 -0.307837 -0.729771  0.614905  0.146371  1.138627  0.046642 -0.402199   \n",
       "\n",
       "         auto_7    auto_8    auto_9  ...  auto_758  auto_759  auto_760  \\\n",
       "0     -0.624635 -0.476621  0.558692  ... -0.384347 -0.661593 -0.654834   \n",
       "1     -0.536153 -0.411402  0.899718  ... -0.442465 -0.755910 -0.579921   \n",
       "2     -0.671038 -0.374610  0.718104  ... -0.376119 -0.652926 -0.665936   \n",
       "3     -0.925455 -0.445610  0.715123  ... -0.629397 -0.687908 -0.533058   \n",
       "4     -0.841166 -0.264719  0.448640  ... -0.326411 -0.068677 -0.875323   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "12325 -0.605195 -0.052753  0.591548  ... -0.557290 -0.947586 -0.491001   \n",
       "12326 -0.494239 -0.307874  0.648765  ... -0.325580 -0.875168 -0.594577   \n",
       "12327 -0.750017 -0.224693  0.906871  ... -0.655012 -0.960211 -0.320545   \n",
       "12328 -0.520967 -0.066664  0.490261  ... -0.362795 -0.692829 -1.060175   \n",
       "12329 -0.733968 -0.330887  0.791850  ... -0.538342 -0.653796 -0.490469   \n",
       "\n",
       "       auto_761  auto_762  auto_763  auto_764  auto_765  auto_766  auto_767  \n",
       "0     -1.278734 -0.733979  0.606833 -0.860581  0.057564 -0.947739 -0.625503  \n",
       "1     -1.346323 -0.807719  0.559565 -0.768464  0.113879 -0.843855 -0.594484  \n",
       "2     -1.259391 -0.708948  0.495114 -0.814280 -0.043755 -0.925378 -0.659469  \n",
       "3     -0.966959 -0.378804  1.258649 -1.047032 -0.608620 -0.450068 -0.855864  \n",
       "4     -0.816320 -0.777433  0.015329 -1.020446 -0.188102 -0.477857 -1.221456  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "12325 -1.417579 -0.197063  0.634306 -0.974436  0.036265 -0.875425 -0.591477  \n",
       "12326 -1.036608 -0.369586  0.804623 -1.185249 -0.101831 -0.884223 -0.866511  \n",
       "12327 -1.063837 -0.535646  0.832245 -1.161984 -0.146790 -0.876181 -0.708760  \n",
       "12328 -0.923082 -0.411730  1.119610 -1.272926 -0.045947 -0.840221 -0.774314  \n",
       "12329 -0.803935 -0.472498  0.787288 -1.185399  0.161853 -1.024348 -0.810102  \n",
       "\n",
       "[12330 rows x 768 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auto_0</th>\n",
       "      <th>auto_1</th>\n",
       "      <th>auto_2</th>\n",
       "      <th>auto_3</th>\n",
       "      <th>auto_4</th>\n",
       "      <th>auto_5</th>\n",
       "      <th>auto_6</th>\n",
       "      <th>auto_7</th>\n",
       "      <th>auto_8</th>\n",
       "      <th>auto_9</th>\n",
       "      <th>...</th>\n",
       "      <th>auto_758</th>\n",
       "      <th>auto_759</th>\n",
       "      <th>auto_760</th>\n",
       "      <th>auto_761</th>\n",
       "      <th>auto_762</th>\n",
       "      <th>auto_763</th>\n",
       "      <th>auto_764</th>\n",
       "      <th>auto_765</th>\n",
       "      <th>auto_766</th>\n",
       "      <th>auto_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.446178</td>\n",
       "      <td>-1.030787</td>\n",
       "      <td>0.651053</td>\n",
       "      <td>0.131997</td>\n",
       "      <td>1.462828</td>\n",
       "      <td>0.029508</td>\n",
       "      <td>-0.295723</td>\n",
       "      <td>-0.624635</td>\n",
       "      <td>-0.476621</td>\n",
       "      <td>0.558692</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.384347</td>\n",
       "      <td>-0.661593</td>\n",
       "      <td>-0.654834</td>\n",
       "      <td>-1.278734</td>\n",
       "      <td>-0.733979</td>\n",
       "      <td>0.606833</td>\n",
       "      <td>-0.860581</td>\n",
       "      <td>0.057564</td>\n",
       "      <td>-0.947739</td>\n",
       "      <td>-0.625503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.465874</td>\n",
       "      <td>-1.181763</td>\n",
       "      <td>0.562184</td>\n",
       "      <td>0.369159</td>\n",
       "      <td>1.582658</td>\n",
       "      <td>0.103490</td>\n",
       "      <td>-0.280516</td>\n",
       "      <td>-0.536153</td>\n",
       "      <td>-0.411402</td>\n",
       "      <td>0.899718</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.442465</td>\n",
       "      <td>-0.755910</td>\n",
       "      <td>-0.579921</td>\n",
       "      <td>-1.346323</td>\n",
       "      <td>-0.807719</td>\n",
       "      <td>0.559565</td>\n",
       "      <td>-0.768464</td>\n",
       "      <td>0.113879</td>\n",
       "      <td>-0.843855</td>\n",
       "      <td>-0.594484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.398899</td>\n",
       "      <td>-1.068048</td>\n",
       "      <td>0.773323</td>\n",
       "      <td>0.165763</td>\n",
       "      <td>1.510350</td>\n",
       "      <td>0.011403</td>\n",
       "      <td>-0.299957</td>\n",
       "      <td>-0.671038</td>\n",
       "      <td>-0.374610</td>\n",
       "      <td>0.718104</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.376119</td>\n",
       "      <td>-0.652926</td>\n",
       "      <td>-0.665936</td>\n",
       "      <td>-1.259391</td>\n",
       "      <td>-0.708948</td>\n",
       "      <td>0.495114</td>\n",
       "      <td>-0.814280</td>\n",
       "      <td>-0.043755</td>\n",
       "      <td>-0.925378</td>\n",
       "      <td>-0.659469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.327914</td>\n",
       "      <td>-0.916163</td>\n",
       "      <td>0.535471</td>\n",
       "      <td>0.040720</td>\n",
       "      <td>1.281561</td>\n",
       "      <td>-0.067109</td>\n",
       "      <td>-0.436066</td>\n",
       "      <td>-0.925455</td>\n",
       "      <td>-0.445610</td>\n",
       "      <td>0.715123</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.629397</td>\n",
       "      <td>-0.687908</td>\n",
       "      <td>-0.533058</td>\n",
       "      <td>-0.966959</td>\n",
       "      <td>-0.378804</td>\n",
       "      <td>1.258649</td>\n",
       "      <td>-1.047032</td>\n",
       "      <td>-0.608620</td>\n",
       "      <td>-0.450068</td>\n",
       "      <td>-0.855864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.193191</td>\n",
       "      <td>-0.339105</td>\n",
       "      <td>0.701786</td>\n",
       "      <td>0.099271</td>\n",
       "      <td>1.795199</td>\n",
       "      <td>-0.328261</td>\n",
       "      <td>-0.968132</td>\n",
       "      <td>-0.841166</td>\n",
       "      <td>-0.264719</td>\n",
       "      <td>0.448640</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326411</td>\n",
       "      <td>-0.068677</td>\n",
       "      <td>-0.875323</td>\n",
       "      <td>-0.816320</td>\n",
       "      <td>-0.777433</td>\n",
       "      <td>0.015329</td>\n",
       "      <td>-1.020446</td>\n",
       "      <td>-0.188102</td>\n",
       "      <td>-0.477857</td>\n",
       "      <td>-1.221456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12325</th>\n",
       "      <td>-0.199234</td>\n",
       "      <td>-0.544771</td>\n",
       "      <td>1.052641</td>\n",
       "      <td>0.258894</td>\n",
       "      <td>1.709730</td>\n",
       "      <td>0.316471</td>\n",
       "      <td>-0.410517</td>\n",
       "      <td>-0.605195</td>\n",
       "      <td>-0.052753</td>\n",
       "      <td>0.591548</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.557290</td>\n",
       "      <td>-0.947586</td>\n",
       "      <td>-0.491001</td>\n",
       "      <td>-1.417579</td>\n",
       "      <td>-0.197063</td>\n",
       "      <td>0.634306</td>\n",
       "      <td>-0.974436</td>\n",
       "      <td>0.036265</td>\n",
       "      <td>-0.875425</td>\n",
       "      <td>-0.591477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12326</th>\n",
       "      <td>-0.544345</td>\n",
       "      <td>-0.855553</td>\n",
       "      <td>0.429286</td>\n",
       "      <td>0.262292</td>\n",
       "      <td>1.596824</td>\n",
       "      <td>-0.283487</td>\n",
       "      <td>-0.641597</td>\n",
       "      <td>-0.494239</td>\n",
       "      <td>-0.307874</td>\n",
       "      <td>0.648765</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.325580</td>\n",
       "      <td>-0.875168</td>\n",
       "      <td>-0.594577</td>\n",
       "      <td>-1.036608</td>\n",
       "      <td>-0.369586</td>\n",
       "      <td>0.804623</td>\n",
       "      <td>-1.185249</td>\n",
       "      <td>-0.101831</td>\n",
       "      <td>-0.884223</td>\n",
       "      <td>-0.866511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12327</th>\n",
       "      <td>-0.238448</td>\n",
       "      <td>-0.706277</td>\n",
       "      <td>0.659115</td>\n",
       "      <td>0.194608</td>\n",
       "      <td>1.261518</td>\n",
       "      <td>0.047830</td>\n",
       "      <td>-0.307249</td>\n",
       "      <td>-0.750017</td>\n",
       "      <td>-0.224693</td>\n",
       "      <td>0.906871</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.655012</td>\n",
       "      <td>-0.960211</td>\n",
       "      <td>-0.320545</td>\n",
       "      <td>-1.063837</td>\n",
       "      <td>-0.535646</td>\n",
       "      <td>0.832245</td>\n",
       "      <td>-1.161984</td>\n",
       "      <td>-0.146790</td>\n",
       "      <td>-0.876181</td>\n",
       "      <td>-0.708760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12328</th>\n",
       "      <td>-0.026563</td>\n",
       "      <td>-0.710416</td>\n",
       "      <td>0.770859</td>\n",
       "      <td>0.307719</td>\n",
       "      <td>0.958489</td>\n",
       "      <td>0.066654</td>\n",
       "      <td>-0.574208</td>\n",
       "      <td>-0.520967</td>\n",
       "      <td>-0.066664</td>\n",
       "      <td>0.490261</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.362795</td>\n",
       "      <td>-0.692829</td>\n",
       "      <td>-1.060175</td>\n",
       "      <td>-0.923082</td>\n",
       "      <td>-0.411730</td>\n",
       "      <td>1.119610</td>\n",
       "      <td>-1.272926</td>\n",
       "      <td>-0.045947</td>\n",
       "      <td>-0.840221</td>\n",
       "      <td>-0.774314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12329</th>\n",
       "      <td>-0.307837</td>\n",
       "      <td>-0.729771</td>\n",
       "      <td>0.614905</td>\n",
       "      <td>0.146371</td>\n",
       "      <td>1.138627</td>\n",
       "      <td>0.046642</td>\n",
       "      <td>-0.402199</td>\n",
       "      <td>-0.733968</td>\n",
       "      <td>-0.330887</td>\n",
       "      <td>0.791850</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.538342</td>\n",
       "      <td>-0.653796</td>\n",
       "      <td>-0.490469</td>\n",
       "      <td>-0.803935</td>\n",
       "      <td>-0.472498</td>\n",
       "      <td>0.787288</td>\n",
       "      <td>-1.185399</td>\n",
       "      <td>0.161853</td>\n",
       "      <td>-1.024348</td>\n",
       "      <td>-0.810102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12330 rows × 768 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T14:17:57.518459Z",
     "start_time": "2024-07-29T14:17:45.063317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# saving bert_df, roberta_df, auto_df to csv\n",
    "bert_df.to_csv('bert_df.csv', index=False)\n",
    "roberta_df.to_csv('roberta_df.csv', index=False)\n",
    "auto_df.to_csv('auto_df.csv', index=False)"
   ],
   "id": "8c145fb21634751a",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T14:48:35.424846Z",
     "start_time": "2024-07-29T14:48:35.421078Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b0acff918e227412",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [0.2559071, 0.10364858, 0.37824497, -0.0081513...\n",
       "1    [0.1890944, 0.014032838, 0.13237679, 0.0806400...\n",
       "2    [0.086543754, 0.10937805, 0.28820986, 0.246597...\n",
       "3    [-0.30589682, 0.17540877, 0.046134617, 0.03900...\n",
       "4    [-0.40894422, -0.1794778, -0.28505862, 0.09229...\n",
       "5    [-0.19625764, 0.067467004, 0.30294913, 0.02172...\n",
       "6    [0.16650629, -0.07729488, 0.46726334, 0.101827...\n",
       "7    [0.24698141, -0.37326866, 0.32759267, 0.288165...\n",
       "8    [-0.15901707, -0.39555636, -0.014359138, 0.284...\n",
       "9    [0.009920761, -0.16916458, 0.30622596, 0.43343...\n",
       "Name: bert, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T15:25:00.905421Z",
     "start_time": "2024-07-29T15:25:00.816546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# combining the columns in bert_df to a single column\n",
    "data['bert'] = bert_df\n",
    "data['roberta'] = roberta_df.apply(lambda x: x.values, axis=1)\n",
    "data['auto'] = auto_df.apply(lambda x: x.values, axis=1)"
   ],
   "id": "d516f4933ec6baa0",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bert_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# combining the columns in bert_df to a single column\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbert\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mbert_df\u001B[49m\n\u001B[1;32m      3\u001B[0m data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mroberta\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m roberta_df\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: x\u001B[38;5;241m.\u001B[39mvalues, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m      4\u001B[0m data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mauto\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m auto_df\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: x\u001B[38;5;241m.\u001B[39mvalues, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'bert_df' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T15:25:10.137008Z",
     "start_time": "2024-07-29T15:25:06.830965Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "# getting data from 'data.xlsx'\n",
    "data = pd.read_excel('data.xlsx')\n",
    "bert_df = pd.read_csv('bert_df.csv')\n",
    "roberta_df = pd.read_csv('roberta_df.csv')\n",
    "auto_df = pd.read_csv('auto_df.csv')\n",
    "data['bert'] = bert_df.apply(lambda x: x.values, axis=1)\n",
    "data['roberta'] = roberta_df.apply(lambda x: x.values, axis=1)\n",
    "data['auto'] = auto_df.apply(lambda x: x.values, axis=1)"
   ],
   "id": "30a0afc35344c26f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T15:36:09.340284Z",
     "start_time": "2024-07-29T15:31:14.825126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Sentiment analysis pipeline\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "\n",
    "def get_sentiment_score(text):\n",
    "    result = sentiment_pipeline(text)[0]\n",
    "    return result['label'], result['score']\n",
    "\n",
    "tqdm.pandas()\n",
    "data[['sentiment_label', 'sentiment_score']] = data['headline'].progress_apply(lambda x: pd.Series(get_sentiment_score(x)))"
   ],
   "id": "aafcdd4f4d4c3c8a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "100%|██████████| 12330/12330 [04:53<00:00, 41.95it/s]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T15:36:27.017347Z",
     "start_time": "2024-07-29T15:36:26.967294Z"
    }
   },
   "cell_type": "code",
   "source": "data.head(10)",
   "id": "4c730d3397481a34",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                            headline       date stock  \\\n",
       "0  Sprucegrove Investment Management Ltd Buys Rya... 2020-05-15  ABEV   \n",
       "1  Westwood Global Investments, LLC Buys Ambev SA... 2020-05-14  ABEV   \n",
       "2  First Eagle Investment Management, LLC Buys Am... 2020-05-12  ABEV   \n",
       "3  Ambev Reports —…—… First Quarter Results Under... 2020-05-07  ABEV   \n",
       "4  5 Latin American Stocks to Consider in Honor o... 2020-05-05  ABEV   \n",
       "5  CORRECTION - Ambev's —…–9 Annual Report on For... 2020-04-15  ABEV   \n",
       "6  Thinking about buying stock in Ambev, Advanced... 2020-02-27  ABEV   \n",
       "7  Fairhaven Wealth Management, LLC Buys First Tr... 2020-02-07  ABEV   \n",
       "8  Investec Asset Management North America, Inc. ... 2020-02-07  ABEV   \n",
       "9  Alta Capital Management Llc Buys PerkinElmer I... 2020-01-30  ABEV   \n",
       "\n",
       "  adjusted_datetime  opening_price  closing_price  \\\n",
       "0        2020-05-15           2.02           2.02   \n",
       "1        2020-05-14           1.97           2.04   \n",
       "2        2020-05-12           2.11           2.02   \n",
       "3        2020-05-07           2.10           2.00   \n",
       "4        2020-05-05           2.18           2.15   \n",
       "5        2020-04-15           2.31           2.29   \n",
       "6        2020-02-27           3.17           3.25   \n",
       "7        2020-02-07           3.92           3.90   \n",
       "8        2020-02-07           3.92           3.90   \n",
       "9        2020-01-30           4.24           4.27   \n",
       "\n",
       "                                                bert  \\\n",
       "0  [0.2559071, 0.10364858, 0.37824497, -0.0081513...   \n",
       "1  [0.1890944, 0.014032838, 0.13237679, 0.0806400...   \n",
       "2  [0.086543754, 0.10937805, 0.28820986, 0.246597...   \n",
       "3  [-0.30589682, 0.17540877, 0.046134617, 0.03900...   \n",
       "4  [-0.40894422, -0.1794778, -0.28505862, 0.09229...   \n",
       "5  [-0.19625764, 0.067467004, 0.30294913, 0.02172...   \n",
       "6  [0.16650629, -0.07729488, 0.46726334, 0.101827...   \n",
       "7  [0.24698141, -0.37326866, 0.32759267, 0.288165...   \n",
       "8  [-0.15901707, -0.39555636, -0.014359138, 0.284...   \n",
       "9  [0.009920761, -0.16916458, 0.30622596, 0.43343...   \n",
       "\n",
       "                                             roberta  \\\n",
       "0  [-0.008698055, 0.047732446, -0.02077271, 0.043...   \n",
       "1  [0.012474053, 0.086053416, 0.037017934, 0.0866...   \n",
       "2  [0.018468218, 0.10328719, 0.036899947, 0.08108...   \n",
       "3  [0.046941273, 0.101946086, -0.021644266, 0.132...   \n",
       "4  [0.12876071, 0.20147394, 0.070045024, -0.10620...   \n",
       "5  [0.0044318372, 0.0933271, 0.025640752, 0.03964...   \n",
       "6  [0.028588777, 0.047011923, -0.036552325, 0.107...   \n",
       "7  [0.0056773126, 0.09306396, -0.04043027, 0.0089...   \n",
       "8  [0.027121706, 0.06587887, 0.026765367, 0.12634...   \n",
       "9  [0.07105354, 0.041213304, -0.036283303, 0.0822...   \n",
       "\n",
       "                                                auto sentiment_label  \\\n",
       "0  [-0.44617787, -1.0307866, 0.65105325, 0.131997...        NEGATIVE   \n",
       "1  [-0.4658743, -1.1817627, 0.5621838, 0.36915895...        POSITIVE   \n",
       "2  [-0.39889896, -1.0680475, 0.7733227, 0.1657631...        NEGATIVE   \n",
       "3  [-0.32791406, -0.91616255, 0.53547114, 0.04071...        NEGATIVE   \n",
       "4  [-0.1931915, -0.33910504, 0.7017856, 0.0992713...        POSITIVE   \n",
       "5  [-0.19258928, -0.84624475, 0.5516808, 0.031516...        NEGATIVE   \n",
       "6  [-0.3209373, -0.90578127, 0.8343287, 0.2536151...        POSITIVE   \n",
       "7  [-0.5195535, -0.9528065, 0.8224277, 0.14866994...        NEGATIVE   \n",
       "8  [-0.5821713, -0.71371293, 0.6212287, 0.3346102...        POSITIVE   \n",
       "9  [-0.5046917, -0.9496251, 0.7434372, 0.10432256...        NEGATIVE   \n",
       "\n",
       "   sentiment_score  \n",
       "0         0.809008  \n",
       "1         0.876715  \n",
       "2         0.952856  \n",
       "3         0.925539  \n",
       "4         0.998113  \n",
       "5         0.978848  \n",
       "6         0.505855  \n",
       "7         0.827918  \n",
       "8         0.880395  \n",
       "9         0.886313  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>date</th>\n",
       "      <th>stock</th>\n",
       "      <th>adjusted_datetime</th>\n",
       "      <th>opening_price</th>\n",
       "      <th>closing_price</th>\n",
       "      <th>bert</th>\n",
       "      <th>roberta</th>\n",
       "      <th>auto</th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sprucegrove Investment Management Ltd Buys Rya...</td>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>ABEV</td>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>2.02</td>\n",
       "      <td>2.02</td>\n",
       "      <td>[0.2559071, 0.10364858, 0.37824497, -0.0081513...</td>\n",
       "      <td>[-0.008698055, 0.047732446, -0.02077271, 0.043...</td>\n",
       "      <td>[-0.44617787, -1.0307866, 0.65105325, 0.131997...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.809008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Westwood Global Investments, LLC Buys Ambev SA...</td>\n",
       "      <td>2020-05-14</td>\n",
       "      <td>ABEV</td>\n",
       "      <td>2020-05-14</td>\n",
       "      <td>1.97</td>\n",
       "      <td>2.04</td>\n",
       "      <td>[0.1890944, 0.014032838, 0.13237679, 0.0806400...</td>\n",
       "      <td>[0.012474053, 0.086053416, 0.037017934, 0.0866...</td>\n",
       "      <td>[-0.4658743, -1.1817627, 0.5621838, 0.36915895...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.876715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>First Eagle Investment Management, LLC Buys Am...</td>\n",
       "      <td>2020-05-12</td>\n",
       "      <td>ABEV</td>\n",
       "      <td>2020-05-12</td>\n",
       "      <td>2.11</td>\n",
       "      <td>2.02</td>\n",
       "      <td>[0.086543754, 0.10937805, 0.28820986, 0.246597...</td>\n",
       "      <td>[0.018468218, 0.10328719, 0.036899947, 0.08108...</td>\n",
       "      <td>[-0.39889896, -1.0680475, 0.7733227, 0.1657631...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.952856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ambev Reports —…—… First Quarter Results Under...</td>\n",
       "      <td>2020-05-07</td>\n",
       "      <td>ABEV</td>\n",
       "      <td>2020-05-07</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2.00</td>\n",
       "      <td>[-0.30589682, 0.17540877, 0.046134617, 0.03900...</td>\n",
       "      <td>[0.046941273, 0.101946086, -0.021644266, 0.132...</td>\n",
       "      <td>[-0.32791406, -0.91616255, 0.53547114, 0.04071...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.925539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5 Latin American Stocks to Consider in Honor o...</td>\n",
       "      <td>2020-05-05</td>\n",
       "      <td>ABEV</td>\n",
       "      <td>2020-05-05</td>\n",
       "      <td>2.18</td>\n",
       "      <td>2.15</td>\n",
       "      <td>[-0.40894422, -0.1794778, -0.28505862, 0.09229...</td>\n",
       "      <td>[0.12876071, 0.20147394, 0.070045024, -0.10620...</td>\n",
       "      <td>[-0.1931915, -0.33910504, 0.7017856, 0.0992713...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.998113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CORRECTION - Ambev's —…–9 Annual Report on For...</td>\n",
       "      <td>2020-04-15</td>\n",
       "      <td>ABEV</td>\n",
       "      <td>2020-04-15</td>\n",
       "      <td>2.31</td>\n",
       "      <td>2.29</td>\n",
       "      <td>[-0.19625764, 0.067467004, 0.30294913, 0.02172...</td>\n",
       "      <td>[0.0044318372, 0.0933271, 0.025640752, 0.03964...</td>\n",
       "      <td>[-0.19258928, -0.84624475, 0.5516808, 0.031516...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.978848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Thinking about buying stock in Ambev, Advanced...</td>\n",
       "      <td>2020-02-27</td>\n",
       "      <td>ABEV</td>\n",
       "      <td>2020-02-27</td>\n",
       "      <td>3.17</td>\n",
       "      <td>3.25</td>\n",
       "      <td>[0.16650629, -0.07729488, 0.46726334, 0.101827...</td>\n",
       "      <td>[0.028588777, 0.047011923, -0.036552325, 0.107...</td>\n",
       "      <td>[-0.3209373, -0.90578127, 0.8343287, 0.2536151...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.505855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Fairhaven Wealth Management, LLC Buys First Tr...</td>\n",
       "      <td>2020-02-07</td>\n",
       "      <td>ABEV</td>\n",
       "      <td>2020-02-07</td>\n",
       "      <td>3.92</td>\n",
       "      <td>3.90</td>\n",
       "      <td>[0.24698141, -0.37326866, 0.32759267, 0.288165...</td>\n",
       "      <td>[0.0056773126, 0.09306396, -0.04043027, 0.0089...</td>\n",
       "      <td>[-0.5195535, -0.9528065, 0.8224277, 0.14866994...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.827918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Investec Asset Management North America, Inc. ...</td>\n",
       "      <td>2020-02-07</td>\n",
       "      <td>ABEV</td>\n",
       "      <td>2020-02-07</td>\n",
       "      <td>3.92</td>\n",
       "      <td>3.90</td>\n",
       "      <td>[-0.15901707, -0.39555636, -0.014359138, 0.284...</td>\n",
       "      <td>[0.027121706, 0.06587887, 0.026765367, 0.12634...</td>\n",
       "      <td>[-0.5821713, -0.71371293, 0.6212287, 0.3346102...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.880395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Alta Capital Management Llc Buys PerkinElmer I...</td>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>ABEV</td>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>4.24</td>\n",
       "      <td>4.27</td>\n",
       "      <td>[0.009920761, -0.16916458, 0.30622596, 0.43343...</td>\n",
       "      <td>[0.07105354, 0.041213304, -0.036283303, 0.0822...</td>\n",
       "      <td>[-0.5046917, -0.9496251, 0.7434372, 0.10432256...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.886313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T15:41:03.879504Z",
     "start_time": "2024-07-29T15:39:42.370130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# saving the data to data_with_features.xlsx\n",
    "data.to_excel('data_with_features.xlsx', index=False)"
   ],
   "id": "c53bbcaec8cce5b7",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8b672419984a3451"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
