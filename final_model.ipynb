{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T10:42:37.026825Z",
     "start_time": "2024-10-15T10:36:25.258567Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def parse_combined_column(s):\n",
    "    if s == '':\n",
    "        return np.zeros(768)\n",
    "    else:\n",
    "        return np.array(eval(s))\n",
    "    \n",
    "\n",
    "df = pd.read_csv('final_data_with_features_2.csv', converters={\n",
    "    'bert': parse_combined_column,\n",
    "    'auto': parse_combined_column,\n",
    "    'roberta': parse_combined_column\n",
    "})"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## processing data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T13:41:48.532005Z",
     "start_time": "2024-10-15T13:41:48.313155Z"
    }
   },
   "source": [
    "# Function to filter rows based on first non-NaN headline\n",
    "def filter_after_first_non_nan(group):\n",
    "    first_non_nan_index = group['headline'].first_valid_index()\n",
    "    if first_non_nan_index is not None:\n",
    "        return group.loc[first_non_nan_index:]\n",
    "    else:\n",
    "        return pd.DataFrame(columns=group.columns)\n",
    "\n",
    "# Apply the function to each group\n",
    "filtered_df = df.groupby('stock').apply(filter_after_first_non_nan).reset_index(drop=True)\n",
    "\n",
    "print(filtered_df)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Open       Close stock        Date  \\\n",
      "0        15.840000   15.930000   AEO  2010-02-12   \n",
      "1        16.040001   16.200001   AEO  2010-02-16   \n",
      "2        16.219999   16.200001   AEO  2010-02-17   \n",
      "3        16.639999   16.700001   AEO  2010-02-18   \n",
      "4        16.639999   16.850000   AEO  2010-02-19   \n",
      "...            ...         ...   ...         ...   \n",
      "135770  237.399994  232.600006  YINN  2020-05-28   \n",
      "135771  240.600006  246.800003  YINN  2020-05-29   \n",
      "135772  251.800003  261.200012  YINN  2020-06-01   \n",
      "135773  268.000000  276.000000  YINN  2020-06-02   \n",
      "135774  283.200012  288.600006  YINN  2020-06-03   \n",
      "\n",
      "                                               headline  \\\n",
      "0           ANF Preview: Targeting International Growth   \n",
      "1       Abercrombie Continues to Make a Splash Overseas   \n",
      "2                                                   NaN   \n",
      "3                                                   NaN   \n",
      "4                                                   NaN   \n",
      "...                                                 ...   \n",
      "135770                                              NaN   \n",
      "135771                                              NaN   \n",
      "135772                                              NaN   \n",
      "135773                                              NaN   \n",
      "135774                                              NaN   \n",
      "\n",
      "                                                     bert  \\\n",
      "0       [-0.4132246077060699, -0.5208402872085571, 0.1...   \n",
      "1       [0.0898434147238731, 0.1315341293811798, -0.10...   \n",
      "2       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "3       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "4       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "...                                                   ...   \n",
      "135770  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "135771  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "135772  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "135773  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "135774  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "\n",
      "                                                  roberta  \\\n",
      "0       [-0.0688138231635093, -0.0178058985620737, 0.0...   \n",
      "1       [0.0873384028673172, 0.1229391023516655, -0.02...   \n",
      "2       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "3       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "4       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "...                                                   ...   \n",
      "135770  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "135771  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "135772  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "135773  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "135774  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "\n",
      "                                                     auto sentiment_label  \\\n",
      "0       [-0.1901581734418869, -0.8065750002861023, 0.9...        POSITIVE   \n",
      "1       [0.7701728940010071, 1.0046442747116089, 1.264...        POSITIVE   \n",
      "2       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...             NaN   \n",
      "3       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...             NaN   \n",
      "4       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...             NaN   \n",
      "...                                                   ...             ...   \n",
      "135770  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...             NaN   \n",
      "135771  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...             NaN   \n",
      "135772  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...             NaN   \n",
      "135773  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...             NaN   \n",
      "135774  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...             NaN   \n",
      "\n",
      "        sentiment_score  \n",
      "0              0.996036  \n",
      "1              0.999591  \n",
      "2                   NaN  \n",
      "3                   NaN  \n",
      "4                   NaN  \n",
      "...                 ...  \n",
      "135770              NaN  \n",
      "135771              NaN  \n",
      "135772              NaN  \n",
      "135773              NaN  \n",
      "135774              NaN  \n",
      "\n",
      "[135775 rows x 10 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/72/g9k3c1cn6n5c2_6cwmxzlx_00000gn/T/ipykernel_4992/4284691702.py:10: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  filtered_df = df.groupby('stock').apply(filter_after_first_non_nan).reset_index(drop=True)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T13:42:14.836626Z",
     "start_time": "2024-10-15T13:42:14.767005Z"
    }
   },
   "source": [
    "def change_sentiment_label(x):\n",
    "    if x == 'POSITIVE':\n",
    "        return 1\n",
    "    elif x == 'NEGATIVE':\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def change_sentiment_score(x):\n",
    "    if -1<=x<=1 :\n",
    "        return x\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "filtered_df['sentiment_label'] = filtered_df['sentiment_label'].apply(change_sentiment_label)\n",
    "filtered_df['sentiment_score'] = filtered_df['sentiment_score'].apply(change_sentiment_score)\n",
    "# set sentiment score to be the sentiment score times the sentiment label\n",
    "filtered_df['sentiment_score'] = filtered_df['sentiment_score'] * filtered_df['sentiment_label']"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T13:42:21.846542Z",
     "start_time": "2024-10-15T13:42:19.719825Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Assuming 'df' is your DataFrame with 'stock', 'Open', and 'Close' columns\n",
    "\n",
    "# Function to apply MinMaxScaler to each group independently\n",
    "def scale_prices(group):\n",
    "    scaler_close = MinMaxScaler(feature_range=(0, 1))\n",
    "    # scaler_open = MinMaxScaler(feature_range=(0, 1))\n",
    "    \n",
    "    # Fit and transform 'Close' prices\n",
    "    group['normalized_closing_price'] = scaler_close.fit_transform(group['Close'].values.reshape(-1, 1))\n",
    "    \n",
    "    # only transform open prices\n",
    "    group['normalized_opening_price'] = scaler_close.transform(group['Open'].values.reshape(-1, 1))\n",
    "    \n",
    "    return group\n",
    "\n",
    "# Apply the scaler independently to each stock\n",
    "filtered_df_same_scaler = filtered_df.groupby('stock').apply(scale_prices)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/72/g9k3c1cn6n5c2_6cwmxzlx_00000gn/T/ipykernel_4992/162186851.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  filtered_df_same_scaler = filtered_df.groupby('stock').apply(scale_prices)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AVGO stock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### more processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgo_based_df = filtered_df_same_scaler[filtered_df_same_scaler['Date'] <= '2020-06-03']\n",
    "avgo_based_df = avgo_based_df[avgo_based_df['Date'] >= '2016-10-31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1y/7v476nfj6wqbyqg8dfczrjph0000gn/T/ipykernel_93171/1022109779.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  avgo_df['other_stocks_normalized_closing_price'] = columns['normalized_closing_price']\n",
      "/var/folders/1y/7v476nfj6wqbyqg8dfczrjph0000gn/T/ipykernel_93171/1022109779.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  avgo_df['other_stocks_normalized_opening_price'] = columns['normalized_opening_price']\n",
      "/var/folders/1y/7v476nfj6wqbyqg8dfczrjph0000gn/T/ipykernel_93171/1022109779.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  avgo_df['other_stocks_sentiment_label'] = columns['sentiment_label']\n",
      "/var/folders/1y/7v476nfj6wqbyqg8dfczrjph0000gn/T/ipykernel_93171/1022109779.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  avgo_df['other_stocks_sentiment_score'] = columns['sentiment_score']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Filter AVGO data\n",
    "avgo_df = avgo_based_df[avgo_based_df['stock'] == 'AVGO']\n",
    "\n",
    "# Get the list of other stocks\n",
    "other_stocks = avgo_based_df['stock'].unique()\n",
    "other_stocks = other_stocks[other_stocks != 'AVGO']\n",
    "\n",
    "# Initialize columns for vectors of other stocks\n",
    "columns = {\n",
    "    'normalized_closing_price': [],\n",
    "    'normalized_opening_price': [],\n",
    "    'sentiment_label': [],\n",
    "    'sentiment_score': []\n",
    "}\n",
    "\n",
    "# Function to aggregate data into vectors for each row corresponding to AVGO stock\n",
    "def aggregate_vectors(date):\n",
    "    vectors = {key: [] for key in columns}\n",
    "    for stock in other_stocks:\n",
    "        stock_data = avgo_based_df[(avgo_based_df['stock'] == stock) & (avgo_based_df['Date'] == date)]\n",
    "        if not stock_data.empty:\n",
    "            vectors['normalized_closing_price'].append(stock_data['normalized_closing_price'].values[0])\n",
    "            vectors['normalized_opening_price'].append(stock_data['normalized_opening_price'].values[0])\n",
    "            vectors['sentiment_label'].append(stock_data['sentiment_label'].values[0])\n",
    "            vectors['sentiment_score'].append(stock_data['sentiment_score'].values[0])\n",
    "        else:\n",
    "            # Append NaN or a specific value if data is missing for this stock/date\n",
    "            # TODO: Handle missing data more appropriately\n",
    "            vectors['normalized_closing_price'].append(0)\n",
    "            vectors['normalized_opening_price'].append(0)\n",
    "            vectors['sentiment_label'].append(0)\n",
    "            vectors['sentiment_score'].append(0)\n",
    "    return vectors\n",
    "\n",
    "# Loop through AVGO dates and aggregate vectors for each date\n",
    "for date in avgo_df['Date']:\n",
    "    vectors = aggregate_vectors(date)\n",
    "    for key in columns:\n",
    "        columns[key].append(vectors[key])\n",
    "\n",
    "# Add the vectors as columns to the AVGO dataframe\n",
    "avgo_df['other_stocks_normalized_closing_price'] = columns['normalized_closing_price']\n",
    "avgo_df['other_stocks_normalized_opening_price'] = columns['normalized_opening_price']\n",
    "avgo_df['other_stocks_sentiment_label'] = columns['sentiment_label']\n",
    "avgo_df['other_stocks_sentiment_score'] = columns['sentiment_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.0662\n",
      "Epoch 2/20, Loss: 0.0169\n",
      "Epoch 3/20, Loss: 0.0049\n",
      "Epoch 4/20, Loss: 0.0019\n",
      "Epoch 5/20, Loss: 0.0013\n",
      "Epoch 6/20, Loss: 0.0008\n",
      "Epoch 7/20, Loss: 0.0007\n",
      "Epoch 8/20, Loss: 0.0006\n",
      "Epoch 9/20, Loss: 0.0005\n",
      "Epoch 10/20, Loss: 0.0004\n",
      "Epoch 11/20, Loss: 0.0004\n",
      "Epoch 12/20, Loss: 0.0003\n",
      "Epoch 13/20, Loss: 0.0003\n",
      "Epoch 14/20, Loss: 0.0003\n",
      "Epoch 15/20, Loss: 0.0002\n",
      "Epoch 16/20, Loss: 0.0002\n",
      "Epoch 17/20, Loss: 0.0002\n",
      "Epoch 18/20, Loss: 0.0002\n",
      "Epoch 19/20, Loss: 0.0001\n",
      "Epoch 20/20, Loss: 0.0001\n",
      "Accuracy of predicting the direction of AVGO stock: 0.9250\n",
      "F1 Score of predicting the direction of AVGO stock: 0.9091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1y/7v476nfj6wqbyqg8dfczrjph0000gn/T/ipykernel_93171/3826278693.py:114: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  previous_closing_prices = AVGO_test['normalized_closing_price'].shift(1).fillna(method='bfill').values\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Define Dataset class with date handling\n",
    "class StockDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.avgo_features = df[['normalized_opening_price', 'sentiment_label', 'sentiment_score']].values\n",
    "        self.other_features = np.concatenate([\n",
    "            # np.stack(df['other_stocks_normalized_closing_price'].values),\n",
    "            np.stack(df['other_stocks_normalized_opening_price'].values),\n",
    "            np.stack(df['other_stocks_sentiment_label'].values),\n",
    "            np.stack(df['other_stocks_sentiment_score'].values)\n",
    "        ], axis=1)\n",
    "        self.targets = df['normalized_closing_price'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.tensor(self.avgo_features[idx], dtype=torch.float32), \n",
    "            torch.tensor(self.other_features[idx], dtype=torch.float32),\n",
    "            torch.tensor(self.targets[idx], dtype=torch.float32)\n",
    "        )\n",
    "\n",
    "# Define the neural network model\n",
    "class StockPredictor(nn.Module):\n",
    "    def __init__(self, avgo_input_size, other_input_size, hidden_size):\n",
    "        super(StockPredictor, self).__init__()\n",
    "        \n",
    "        # AVGO-specific branch\n",
    "        self.avgo_branch = nn.Sequential(\n",
    "            nn.Linear(avgo_input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Other stocks branch\n",
    "        self.other_branch = nn.Sequential(\n",
    "            nn.Linear(other_input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Fusion layer combining AVGO and other stocks\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 1)  # Output layer for closing price prediction\n",
    "        )\n",
    "\n",
    "    def forward(self, avgo_features, other_features):\n",
    "        # Forward pass for AVGO\n",
    "        avgo_out = self.avgo_branch(avgo_features)\n",
    "        \n",
    "        # Forward pass for other stocks\n",
    "        other_out = self.other_branch(other_features)\n",
    "        \n",
    "        # Concatenate outputs from both branches\n",
    "        combined = torch.cat((avgo_out, other_out), dim=1)\n",
    "        \n",
    "        # Final prediction\n",
    "        return self.fusion(combined).squeeze()\n",
    "\n",
    "# Split data into training and testing sets\n",
    "AVGO_train = avgo_df[avgo_df['Date'] < '2020-02-10']\n",
    "AVGO_test = avgo_df[avgo_df['Date'] >= '2020-02-10']\n",
    "\n",
    "# Prepare the datasets\n",
    "train_dataset = StockDataset(AVGO_train)\n",
    "test_dataset = StockDataset(AVGO_test)\n",
    "\n",
    "# Define DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Initialize the model\n",
    "avgo_input_size = 3  # AVGO features: opening price, sentiment label, sentiment score\n",
    "other_input_size = train_dataset.other_features.shape[1]  # Combined other stocks features\n",
    "hidden_size = 64\n",
    "model = StockPredictor(avgo_input_size, other_input_size, hidden_size)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for avgo_features, other_features, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(avgo_features, other_features)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss / len(train_loader):.4f}')\n",
    "\n",
    "# Evaluation on test data\n",
    "model.eval()\n",
    "correct_direction = 0\n",
    "total = 0\n",
    "all_actual_directions = []\n",
    "all_predicted_directions = []\n",
    "\n",
    "# Prepare previous day's closing prices for direction comparison\n",
    "previous_closing_prices = AVGO_test['normalized_closing_price'].shift(1).fillna(method='bfill').values\n",
    "\n",
    "with torch.no_grad():\n",
    "    for avgo_features, other_features, targets in test_loader:\n",
    "        outputs = model(avgo_features, other_features)\n",
    "        predicted_prices = outputs.numpy()\n",
    "\n",
    "        # Compare directions: 1 if price increased, 0 if decreased\n",
    "        predicted_direction = (predicted_prices > previous_closing_prices[:len(predicted_prices)]).astype(int)\n",
    "        actual_direction = (targets.numpy() > previous_closing_prices[:len(targets)]).astype(int)\n",
    "\n",
    "        all_predicted_directions.extend(predicted_direction)\n",
    "        all_actual_directions.extend(actual_direction)\n",
    "\n",
    "        correct_direction += np.sum(predicted_direction == actual_direction)\n",
    "        total += len(actual_direction)\n",
    "\n",
    "# Calculate accuracy and F1 score\n",
    "accuracy = accuracy_score(all_actual_directions, all_predicted_directions)\n",
    "f1 = f1_score(all_actual_directions, all_predicted_directions)\n",
    "\n",
    "print(f\"Accuracy of predicting the direction of AVGO stock: {accuracy:.4f}\")\n",
    "print(f\"F1 Score of predicting the direction of AVGO stock: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INTC stock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### more processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "intc_based_df = filtered_df_same_scaler[filtered_df_same_scaler['Date'] <= '2020-06-03']\n",
    "intc_based_df = intc_based_df[intc_based_df['Date'] >= '2018-10-25']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1y/7v476nfj6wqbyqg8dfczrjph0000gn/T/ipykernel_93171/3849655031.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  intc_df['other_stocks_normalized_closing_price'] = columns['normalized_closing_price']\n",
      "/var/folders/1y/7v476nfj6wqbyqg8dfczrjph0000gn/T/ipykernel_93171/3849655031.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  intc_df['other_stocks_normalized_opening_price'] = columns['normalized_opening_price']\n",
      "/var/folders/1y/7v476nfj6wqbyqg8dfczrjph0000gn/T/ipykernel_93171/3849655031.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  intc_df['other_stocks_sentiment_label'] = columns['sentiment_label']\n",
      "/var/folders/1y/7v476nfj6wqbyqg8dfczrjph0000gn/T/ipykernel_93171/3849655031.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  intc_df['other_stocks_sentiment_score'] = columns['sentiment_score']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Filter INTC data\n",
    "intc_df = intc_based_df[intc_based_df['stock'] == 'INTC']\n",
    "\n",
    "# Get the list of other stocks\n",
    "other_stocks = intc_based_df['stock'].unique()\n",
    "other_stocks = other_stocks[other_stocks != 'INTC']\n",
    "\n",
    "# Initialize columns for vectors of other stocks\n",
    "columns = {\n",
    "    'normalized_closing_price': [],\n",
    "    'normalized_opening_price': [],\n",
    "    'sentiment_label': [],\n",
    "    'sentiment_score': []\n",
    "}\n",
    "\n",
    "# Function to aggregate data into vectors for each row corresponding to INTC stock\n",
    "def aggregate_vectors(date):\n",
    "    vectors = {key: [] for key in columns}\n",
    "    for stock in other_stocks:\n",
    "        stock_data = intc_based_df[(intc_based_df['stock'] == stock) & (intc_based_df['Date'] == date)]\n",
    "        if not stock_data.empty:\n",
    "            vectors['normalized_closing_price'].append(stock_data['normalized_closing_price'].values[0])\n",
    "            vectors['normalized_opening_price'].append(stock_data['normalized_opening_price'].values[0])\n",
    "            vectors['sentiment_label'].append(stock_data['sentiment_label'].values[0])\n",
    "            vectors['sentiment_score'].append(stock_data['sentiment_score'].values[0])\n",
    "        else:\n",
    "            # Append NaN or a specific value if data is missing for this stock/date\n",
    "            # TODO: Handle missing data more appropriately\n",
    "            vectors['normalized_closing_price'].append(0)\n",
    "            vectors['normalized_opening_price'].append(0)\n",
    "            vectors['sentiment_label'].append(0)\n",
    "            vectors['sentiment_score'].append(0)\n",
    "    return vectors\n",
    "\n",
    "# Loop through INTC dates and aggregate vectors for each date\n",
    "for date in intc_df['Date']:\n",
    "    vectors = aggregate_vectors(date)\n",
    "    for key in columns:\n",
    "        columns[key].append(vectors[key])\n",
    "\n",
    "# Add the vectors as columns to the INTC dataframe\n",
    "intc_df['other_stocks_normalized_closing_price'] = columns['normalized_closing_price']\n",
    "intc_df['other_stocks_normalized_opening_price'] = columns['normalized_opening_price']\n",
    "intc_df['other_stocks_sentiment_label'] = columns['sentiment_label']\n",
    "intc_df['other_stocks_sentiment_score'] = columns['sentiment_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.0683\n",
      "Epoch 2/20, Loss: 0.0347\n",
      "Epoch 3/20, Loss: 0.0251\n",
      "Epoch 4/20, Loss: 0.0174\n",
      "Epoch 5/20, Loss: 0.0090\n",
      "Epoch 6/20, Loss: 0.0036\n",
      "Epoch 7/20, Loss: 0.0018\n",
      "Epoch 8/20, Loss: 0.0010\n",
      "Epoch 9/20, Loss: 0.0011\n",
      "Epoch 10/20, Loss: 0.0011\n",
      "Epoch 11/20, Loss: 0.0011\n",
      "Epoch 12/20, Loss: 0.0007\n",
      "Epoch 13/20, Loss: 0.0006\n",
      "Epoch 14/20, Loss: 0.0006\n",
      "Epoch 15/20, Loss: 0.0004\n",
      "Epoch 16/20, Loss: 0.0004\n",
      "Epoch 17/20, Loss: 0.0004\n",
      "Epoch 18/20, Loss: 0.0003\n",
      "Epoch 19/20, Loss: 0.0003\n",
      "Epoch 20/20, Loss: 0.0002\n",
      "Accuracy of predicting the direction of INTC stock: 0.8750\n",
      "F1 Score of predicting the direction of INTC stock: 0.8571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1y/7v476nfj6wqbyqg8dfczrjph0000gn/T/ipykernel_93171/2076475858.py:114: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  previous_closing_prices = INTC_test['normalized_closing_price'].shift(1).fillna(method='bfill').values\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Define Dataset class with date handling\n",
    "class StockDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.intc_features = df[['normalized_opening_price', 'sentiment_label', 'sentiment_score']].values\n",
    "        self.other_features = np.concatenate([\n",
    "            # np.stack(df['other_stocks_normalized_closing_price'].values),\n",
    "            np.stack(df['other_stocks_normalized_opening_price'].values),\n",
    "            np.stack(df['other_stocks_sentiment_label'].values),\n",
    "            np.stack(df['other_stocks_sentiment_score'].values)\n",
    "        ], axis=1)\n",
    "        self.targets = df['normalized_closing_price'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.tensor(self.intc_features[idx], dtype=torch.float32), \n",
    "            torch.tensor(self.other_features[idx], dtype=torch.float32),\n",
    "            torch.tensor(self.targets[idx], dtype=torch.float32)\n",
    "        )\n",
    "\n",
    "# Define the neural network model\n",
    "class StockPredictor(nn.Module):\n",
    "    def __init__(self, intc_input_size, other_input_size, hidden_size):\n",
    "        super(StockPredictor, self).__init__()\n",
    "        \n",
    "        # INTC-specific branch\n",
    "        self.intc_branch = nn.Sequential(\n",
    "            nn.Linear(intc_input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Other stocks branch\n",
    "        self.other_branch = nn.Sequential(\n",
    "            nn.Linear(other_input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Fusion layer combining INTC and other stocks\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 1)  # Output layer for closing price prediction\n",
    "        )\n",
    "\n",
    "    def forward(self, intc_features, other_features):\n",
    "        # Forward pass for INTC\n",
    "        intc_out = self.intc_branch(intc_features)\n",
    "        \n",
    "        # Forward pass for other stocks\n",
    "        other_out = self.other_branch(other_features)\n",
    "        \n",
    "        # Concatenate outputs from both branches\n",
    "        combined = torch.cat((intc_out, other_out), dim=1)\n",
    "        \n",
    "        # Final prediction\n",
    "        return self.fusion(combined).squeeze()\n",
    "\n",
    "# Split data into training and testing sets\n",
    "INTC_train = intc_df[intc_df['Date'] < '2020-02-10']\n",
    "INTC_test = intc_df[intc_df['Date'] >= '2020-02-10']\n",
    "\n",
    "# Prepare the datasets\n",
    "train_dataset = StockDataset(INTC_train)\n",
    "test_dataset = StockDataset(INTC_test)\n",
    "\n",
    "# Define DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Initialize the model\n",
    "intc_input_size = 3  # INTC features: opening price, sentiment label, sentiment score\n",
    "other_input_size = train_dataset.other_features.shape[1]  # Combined other stocks features\n",
    "hidden_size = 64\n",
    "model = StockPredictor(intc_input_size, other_input_size, hidden_size)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for intc_features, other_features, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(intc_features, other_features)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss / len(train_loader):.4f}')\n",
    "\n",
    "# Evaluation on test data\n",
    "model.eval()\n",
    "correct_direction = 0\n",
    "total = 0\n",
    "all_actual_directions = []\n",
    "all_predicted_directions = []\n",
    "\n",
    "# Prepare previous day's closing prices for direction comparison\n",
    "previous_closing_prices = INTC_test['normalized_closing_price'].shift(1).fillna(method='bfill').values\n",
    "\n",
    "with torch.no_grad():\n",
    "    for intc_features, other_features, targets in test_loader:\n",
    "        outputs = model(intc_features, other_features)\n",
    "        predicted_prices = outputs.numpy()\n",
    "\n",
    "        # Compare directions: 1 if price increased, 0 if decreased\n",
    "        predicted_direction = (predicted_prices > previous_closing_prices[:len(predicted_prices)]).astype(int)\n",
    "        actual_direction = (targets.numpy() > previous_closing_prices[:len(targets)]).astype(int)\n",
    "\n",
    "        all_predicted_directions.extend(predicted_direction)\n",
    "        all_actual_directions.extend(actual_direction)\n",
    "\n",
    "        correct_direction += np.sum(predicted_direction == actual_direction)\n",
    "        total += len(actual_direction)\n",
    "\n",
    "# Calculate accuracy and F1 score\n",
    "accuracy = accuracy_score(all_actual_directions, all_predicted_directions)\n",
    "f1 = f1_score(all_actual_directions, all_predicted_directions)\n",
    "\n",
    "print(f\"Accuracy of predicting the direction of INTC stock: {accuracy:.4f}\")\n",
    "print(f\"F1 Score of predicting the direction of INTC stock: {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_ensembled_FA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
